{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n",
    "assert tf.config.list_physical_devices('GPU'), \"No GPU detected: Check your Kaggle environment settings.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ConvNeXtTiny\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# from keras_flops import get_flops\n",
    "\n",
    "\n",
    "IMG_SIZE = (224, 224)  # Adjust as needed\n",
    "BATCH_SIZE = 32\n",
    "DROPOUT_RATE = 0.3\n",
    "INITIAL_LR = 0.001\n",
    "EPOCHS = 50\n",
    "SEED = 42\n",
    "\n",
    "train_dir = '/kaggle/input/cwd30-corn-grass-weeds-new-aug-split-33/data_final_split/train'\n",
    "val_dir = '/kaggle/input/cwd30-corn-grass-weeds-new-aug-split-33/data_final_split/val'\n",
    "test_dir = '/kaggle/input/cwd30-corn-grass-weeds-new-aug-split-33/data_final_split/test'\n",
    "\n",
    "datagen_args = dict(rescale=1./255)\n",
    "train_gen = ImageDataGenerator(**datagen_args)\n",
    "val_gen = ImageDataGenerator(**datagen_args)\n",
    "test_gen = ImageDataGenerator(**datagen_args)\n",
    "train_flow = train_gen.flow_from_directory(\n",
    "    train_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical', shuffle=True, seed=SEED)\n",
    "val_flow = val_gen.flow_from_directory(\n",
    "    val_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical', shuffle=False)\n",
    "test_flow = test_gen.flow_from_directory(\n",
    "    test_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical', shuffle=False)\n",
    "num_classes = train_flow.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ConvNeXtTiny(\n",
    "    include_top=False, \n",
    "    weights='imagenet', \n",
    "    input_shape=IMG_SIZE + (3,)\n",
    ")\n",
    "\n",
    "base_model.trainable = True\n",
    "\n",
    "# Add custom classification head\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dropout(DROPOUT_RATE)(x)\n",
    "\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(DROPOUT_RATE)(x)\n",
    "\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(DROPOUT_RATE)(x)\n",
    "\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(DROPOUT_RATE)(x)\n",
    "\n",
    "x = Dense(128, activation='relu')(x)\n",
    "\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.AdamW(\n",
    "    learning_rate=INITIAL_LR, \n",
    "    weight_decay=0.01\n",
    ")\n",
    "\n",
    "print(\"Compiling model...\")\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nModel Summary:\")\n",
    "print(f\"Total parameters: {model.count_params():,}\")\n",
    "print(f\"Trainable parameters: {sum([tf.keras.backend.count_params(w) for w in model.trainable_weights]):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cb = ModelCheckpoint(\n",
    "    \"best_ConvNeXtTiny_model.h5\",\n",
    "    save_best_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "earlystop_cb = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=10, \n",
    "    restore_best_weights=True,\n",
    "    min_delta=0.001,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks = [checkpoint_cb, earlystop_cb, reduce_lr]\n",
    "\n",
    "print(\"Starting training \")\n",
    "!curl -d \"Train Start\" ntfy.sh/model_complete\n",
    "\n",
    "# Train the whole model on your dataset\n",
    "history = model.fit(\n",
    "    train_flow,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_flow,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Training completed!\")\n",
    "!curl -d \"Train Complete\" ntfy.sh/model_complete\n",
    "\n",
    "with open('training_history.json', 'w') as f:\n",
    "    json.dump(history.history,f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_flow.reset()\n",
    "y_true = test_flow.classes\n",
    "y_pred_probs = model.predict(test_flow)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "target_names = list(test_flow.class_indices.keys())\n",
    "report = classification_report(y_true, y_pred, target_names=target_names, digits=4, output_dict=True)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "test_loss, test_acc = model.evaluate(test_flow, verbose=0)\n",
    "\n",
    "# Precision, Recall, F1 (macro avg)\n",
    "precision = report[\"macro avg\"][\"precision\"]\n",
    "recall = report[\"macro avg\"][\"recall\"]\n",
    "f1 = report[\"macro avg\"][\"f1-score\"]\n",
    "\n",
    "# GFLOPS & Params\n",
    "# flops = get_flops(model, batch_size=1)\n",
    "num_params = model.count_params()\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "# print(f\"GFLOPS: {flops/1e9:.4f}\")\n",
    "print(f\"Parameters: {num_params}\")\n",
    "\n",
    "# Confusion Matrix \n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(target_names))\n",
    "plt.xticks(tick_marks, target_names, rotation=45)\n",
    "plt.yticks(tick_marks, target_names)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "\n",
    "# Loss/Accuracy Curves \n",
    "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.legend(); plt.title(\"Loss over epochs\"); plt.show()\n",
    "plt.plot(history.history[\"accuracy\"], label=\"Training Acc\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"Validation Acc\")\n",
    "plt.legend(); plt.title(\"Accuracy over epochs\"); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('ConvNeXtTiny_final_model.keras')\n",
    "model.save_weights('ConvNeXtTiny_final.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results = {\n",
    "    \"Model\": [\"ConvNeXtTiny\"],\n",
    "    \"Params\": [num_params],\n",
    "    # \"GFLOPS\": [f\"{flops/1e9:.4f}\"],\n",
    "    \"Test Loss\": [f\"{test_loss:.4f}\"],\n",
    "    \"Test Acc\": [f\"{test_acc:.4f}\"],\n",
    "    \"Precision\": [f\"{precision:.4f}\"],\n",
    "    \"Recall\": [f\"{recall:.4f}\"],\n",
    "    \"F1\": [f\"{f1:.4f}\"]\n",
    "}\n",
    "df = pd.DataFrame(results)\n",
    "print(df.to_markdown(index=False))\n",
    "\n",
    "\n",
    "import random\n",
    "sample_idx = random.sample(range(test_flow.n), 10)\n",
    "for idx in sample_idx:\n",
    "    img_path = test_flow.filepaths[idx]\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=IMG_SIZE)\n",
    "    plt.imshow(img)\n",
    "    true_label = target_names[y_true[idx]]\n",
    "    pred_label = target_names[y_pred[idx]]\n",
    "    plt.title(f\"True: {true_label} | Pred: {pred_label}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "!curl -d \"Finished\" ntfy.sh/model_complete"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8038968,
     "sourceId": 12718872,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8037358,
     "sourceId": 12725604,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8048131,
     "sourceId": 12732656,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8057173,
     "sourceId": 12745697,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 426111,
     "modelInstanceId": 408256,
     "sourceId": 518066,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
